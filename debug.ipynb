{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import finnhub\n",
    "import datetime\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.core_plugins.time_plugin import TimePlugin\n",
    "from semantic_kernel.core_plugins.math_plugin import MathPlugin\n",
    "from semantic_kernel.core_plugins.text_plugin import TextPlugin\n",
    "from semantic_kernel.prompt_template import PromptTemplateConfig\n",
    "\n",
    "\n",
    "class FinnhubPlugin:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = finnhub.Client(api_key=api_key)\n",
    "\n",
    "    def fetch_latest_investment_news(self, category=\"top news\", min_id=0):\n",
    "        try:\n",
    "            news = self.client.general_news(category, min_id=min_id)\n",
    "            formatted_news = []\n",
    "            for item in news:\n",
    "                formatted_news.append(\n",
    "                    {\n",
    "                        \"headline\": item[\"headline\"],\n",
    "                        \"source\": item[\"source\"],\n",
    "                        \"date\": datetime.datetime.fromtimestamp(\n",
    "                            item[\"datetime\"]\n",
    "                        ).strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                        \"summary\": item[\"summary\"],\n",
    "                        \"url\": item[\"url\"],\n",
    "                        \"image\": item[\"image\"],\n",
    "                    }\n",
    "                )\n",
    "            return formatted_news\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "# API Keys from environment variables\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "FINNHUB_API_KEY = os.environ[\"FINNHUB_API_KEY\"]\n",
    "\n",
    "# Initialize Finnhub plugin\n",
    "finnhub_plugin = FinnhubPlugin(FINNHUB_API_KEY)\n",
    "\n",
    "# Initialize the Semantic Kernel\n",
    "kernel = Kernel()\n",
    "\n",
    "# Add OpenAI services\n",
    "gpt4o_service_id = \"chat-gpt-4o\"\n",
    "kernel.add_service(\n",
    "    OpenAIChatCompletion(\n",
    "        service_id=gpt4o_service_id, api_key=OPENAI_API_KEY, ai_model_id=\"gpt-4o\"\n",
    "    )\n",
    ")\n",
    "\n",
    "gpt35_service_id = \"chat-gpt-35\"\n",
    "kernel.add_service(\n",
    "    OpenAIChatCompletion(\n",
    "        service_id=gpt35_service_id, api_key=OPENAI_API_KEY, ai_model_id=\"gpt-3.5-turbo\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add core plugins\n",
    "kernel.add_plugin(TimePlugin(), \"time\")\n",
    "kernel.add_plugin(MathPlugin(), \"math\")\n",
    "kernel.add_plugin(TextPlugin(), \"text\")\n",
    "\n",
    "# Add Finnhub plugin to kernel\n",
    "kernel.add_plugin(finnhub_plugin, \"finnhub\")\n",
    "\n",
    "# Define the request settings\n",
    "req_settings = kernel.get_prompt_execution_settings_from_service_id(gpt35_service_id)\n",
    "req_settings.max_tokens = 2000\n",
    "req_settings.temperature = 0.7\n",
    "req_settings.top_p = 0.8\n",
    "\n",
    "# Define the prompt template for summarizing investment news\n",
    "investment_news_prompt_template = \"\"\"\n",
    "Summarize 5 top news bullet points. News: {{$news}}\n",
    "\"\"\"\n",
    "\n",
    "# Create the prompt template configuration\n",
    "investment_news_prompt_template_config = PromptTemplateConfig(\n",
    "    template=investment_news_prompt_template,\n",
    "    name=\"investment_news_summary\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    execution_settings=req_settings,\n",
    ")\n",
    "\n",
    "# Create the function using the prompt template configuration\n",
    "investment_news_summary_function = kernel.add_function(\n",
    "    function_name=\"investment_news_summary_function\",\n",
    "    plugin_name=\"investment_news_plugin\",\n",
    "    prompt_template_config=investment_news_prompt_template_config,\n",
    ")\n",
    "\n",
    "news_summary = await kernel.invoke(\n",
    "    investment_news_summary_function, news=finnhub_plugin.fetch_latest_investment_news()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionResult(function=KernelFunctionMetadata(name='investment_news_summary_function', plugin_name='investment_news_plugin', description=None, parameters=[KernelParameterMetadata(name='news', description='', default_value='', type_='', is_required=True, type_object=None, schema_data={'type': 'object'})], is_prompt=True, is_asynchronous=True, return_parameter=KernelParameterMetadata(name='return', description='The completion result', default_value=None, type_='FunctionResult', is_required=True, type_object=None, schema_data=None), additional_properties=None), value=[ChatMessageContent(inner_content=ChatCompletion(id='chatcmpl-9UlDxFjHo0dzUeSpuAKJ1GElba19U', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"1. Former President Donald Trump has been found dead in his apartment.\\n2. The cause of Trump's death has not been disclosed.\\n3. Trump's death has shocked and saddened many across the country.\\n4. Tributes and condolences are pouring in from political figures and supporters.\\n5. Investigations are ongoing to determine the circumstances surrounding Trump's death.\", role='assistant', function_call=None, tool_calls=None))], created=1717118397, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=70, prompt_tokens=29, total_tokens=99)), ai_model_id='gpt-3.5-turbo', metadata={'logprobs': None, 'id': 'chatcmpl-9UlDxFjHo0dzUeSpuAKJ1GElba19U', 'created': 1717118397, 'system_fingerprint': None, 'usage': CompletionUsage(completion_tokens=70, prompt_tokens=29, total_tokens=99)}, role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[TextContent(inner_content=None, ai_model_id=None, metadata={}, text=\"1. Former President Donald Trump has been found dead in his apartment.\\n2. The cause of Trump's death has not been disclosed.\\n3. Trump's death has shocked and saddened many across the country.\\n4. Tributes and condolences are pouring in from political figures and supporters.\\n5. Investigations are ongoing to determine the circumstances surrounding Trump's death.\", encoding=None)], encoding=None, finish_reason=<FinishReason.STOP: 'stop'>)], metadata={'arguments': {'news': 'Donald Trump foudn dead in his apartment.'}, 'metadata': [{'logprobs': None, 'id': 'chatcmpl-9UlDxFjHo0dzUeSpuAKJ1GElba19U', 'created': 1717118397, 'system_fingerprint': None, 'usage': CompletionUsage(completion_tokens=70, prompt_tokens=29, total_tokens=99)}], 'messages': ChatHistory(messages=[ChatMessageContent(inner_content=None, ai_model_id=None, metadata={}, role=<AuthorRole.USER: 'user'>, name=None, items=[TextContent(inner_content=None, ai_model_id=None, metadata={}, text='Summarize 5 top news bullet points. News: Donald Trump foudn dead in his apartment.', encoding=None)], encoding=None, finish_reason=None)])})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template for summarizing\n",
    "summarize_prompt_template = \"\"\"\n",
    "{{$input}}\n",
    "\n",
    "One line TLDR with the fewest words. Last time you said: {{$history}}. Explain also what day it is Context: {{time.today}}.\n",
    "\"\"\"\n",
    "\n",
    "# Create the prompt template configuration\n",
    "summarize_prompt_template_config = PromptTemplateConfig(\n",
    "    template=summarize_prompt_template,\n",
    "    name=\"summarize\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    execution_settings=req_settings,\n",
    ")\n",
    "\n",
    "# Create the summarize function using the prompt template configuration\n",
    "summarize = kernel.add_function(\n",
    "    function_name=\"summarize_function\",\n",
    "    plugin_name=\"summarize_plugin\",\n",
    "    prompt_template_config=summarize_prompt_template_config,\n",
    ")\n",
    "\n",
    "\n",
    "# Run your prompt\n",
    "# Note: functions are run asynchronously\n",
    "async def main():\n",
    "    # Summarize the laws of thermodynamics\n",
    "    thermodynamics_result = await kernel.invoke(\n",
    "        summarize,\n",
    "        input=\"\"\"\n",
    "    1st Law of Thermodynamics - Energy cannot be created or destroyed.\n",
    "    2nd Law of Thermodynamics - For a spontaneous process, the entropy of the universe increases.\n",
    "    3rd Law of Thermodynamics - A perfect crystal at zero Kelvin has zero entropy.\"\"\",\n",
    "        history=\"\",\n",
    "    )\n",
    "    print(thermodynamics_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st Law: Energy is conserved.\n",
      "2nd Law: Entropy increases in spontaneous processes.\n",
      "3rd Law: Zero entropy at absolute zero.\n",
      "Today is Thursday, 30 May, 2024.\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup language models\n",
    "gpt4_kernel = sk.Kernel()\n",
    "gpt4_kernel.add_service(\n",
    "    OpenAIChatCompletion(\n",
    "        service_id=\"gpt4o\",\n",
    "        ai_model_id=\"gpt-4o\",\n",
    "        api_key=OPENAI_API_KEY\n",
    "    ),\n",
    ")\n",
    "gpt3_kernel = sk.Kernel()\n",
    "gpt3_kernel.add_service(\n",
    "    OpenAIChatCompletion(\n",
    "        service_id=\"gpt3.5-turbo\",\n",
    "        ai_model_id=\"gpt-3.5-turbo\",\n",
    "        api_key=OPENAI_API_KEY\n",
    "    ),\n",
    ")\n",
    "\n",
    "# examples of adding functions to the kernels\n",
    "gpt4_kernel.add_function(function_name=\"get_stock_price\", plugin_name=\"stock_info_plugin\", prompt=\"What is the stock price of {symbol}?\")\n",
    "gpt4_kernel.add_function(function_name=\"get_company_profile\", plugin_name=\"stock_info_plugin\", prompt=\"Tell me about the company {symbol}.\")\n",
    "gpt4_kernel.add_function(function_name=\"get_historical_data\", plugin_name=\"stock_info_plugin\", prompt=\"Give me the historical data for {symbol}.\")\n",
    "gpt3_kernel.add_function(function_name=\"get_stock_price\", plugin_name=\"stock_info_plugin\", prompt=\"What is the stock price of {symbol}?\")\n",
    "gpt3_kernel.add_function(function_name=\"get_company_profile\", plugin_name=\"stock_info_plugin\", prompt=\"Tell me about the company {symbol}.\")\n",
    "gpt3_kernel.add_function(function_name=\"get_historical_data\", plugin_name=\"stock_info_plugin\", prompt=\"Give me the historical data for {symbol}.\")\n",
    "\n",
    "\n",
    "# for using Phi-3 locally\n",
    "qa_pipeline = pipeline('text-generation', model='microsoft/Phi-3-mini-128k-instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_function = gpt3_kernel.get_function(function_name=\"get_stock_price\", plugin_name=\"stock_info_plugin\")\n",
    "request_settings = {\n",
    "    \"prompt\": \"What is the stock price of AAPL?\",\n",
    "    \"max_tokens\": 150,  # Adjust as needed\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.9\n",
    "}\n",
    "\n",
    "# Invoke the function\n",
    "result = await gpt3_kernel.invoke(test_function, **request_settings)\n",
    "print(result.get_inner_content().to_dict()['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finnhub_client = finnhub.Client(FINNHUB_API_KEY)\n",
    "trading_client = TradingClient(ALPACA_API_KEY, ALPACA_SECRET_KEY, paper=True)\n",
    "\n",
    "# Initialize FAISS index\n",
    "d = 512  # Example dimensionality\n",
    "index = faiss.IndexIVFPQ(faiss.IndexFlatL2(d), d, 256, 8, 8)\n",
    "symbol_mapping = {}\n",
    "\n",
    "def fetch_stock_symbols():\n",
    "    #TODO: Fetch stock symbols from API\n",
    "    return [\"AAPL\", \"MSFT\", \"AMZN\", \"GOOGL\", \"FB\", \"JPM\", \"JNJ\", \"NVDA\", \"PG\", \"DIS\"]\n",
    "\n",
    "def fetch_stock_data(symbol):\n",
    "    # Example function to fetch stock data\n",
    "    url = f\"https://api.example.com/stock/{symbol}/fundamentals\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return data\n",
    "\n",
    "def preprocess_data(data):\n",
    "    # Convert your data to a vector\n",
    "    # Ensure the order of features matches the dimensionality 'd'\n",
    "    features = ['open', 'high', 'low', 'close', 'volume']\n",
    "    vector = np.array([data[feature] for feature in features]).astype('float32')\n",
    "    return vector\n",
    "\n",
    "def store_data_in_faiss(symbol, data):\n",
    "    vector = preprocess_data(data)\n",
    "    index.add(np.array([vector]))\n",
    "    symbol_mapping[index.ntotal - 1] = symbol\n",
    "\n",
    "def fetch_latest_data_from_faiss():\n",
    "    # Example function to fetch latest data from FAISS\n",
    "    k = 1  # Number of nearest neighbors\n",
    "    query_vector = np.random.random(d).astype('float32')  # Example query vector\n",
    "    D, I = index.search(np.array([query_vector]), k)\n",
    "    symbols = [symbol_mapping[i] for i in I[0]]\n",
    "    return symbols\n",
    "\n",
    "def create_debate_prompt(stock_data):\n",
    "    prompt = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a financial expert.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Analyze the following stock data and debate: {stock_data}\"}\n",
    "    ]\n",
    "    return prompt\n",
    "\n",
    "def debate_agents(stock_data):\n",
    "    prompt = create_debate_prompt(stock_data)\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=prompt,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return parse_debate_response(response)\n",
    "\n",
    "def parse_debate_response(response):\n",
    "    decisions = [message['content'] for message in response['choices']]\n",
    "    decision_counts = {\"buy\": 0, \"sell\": 0, \"hold\": 0}\n",
    "    for decision in decisions:\n",
    "        if \"buy\" in decision:\n",
    "            decision_counts[\"buy\"] += 1\n",
    "        elif \"sell\" in decision:\n",
    "            decision_counts[\"sell\"] += 1\n",
    "        else:\n",
    "            decision_counts[\"hold\"] += 1\n",
    "    return max(decision_counts, key=decision_counts.get)\n",
    "\n",
    "def execute_trade(decision, symbol):\n",
    "    if decision == 'buy':\n",
    "        order = MarketOrderRequest(\n",
    "            symbol=symbol,\n",
    "            qty=1,\n",
    "            side=OrderSide.BUY,\n",
    "            time_in_force=TimeInForce.GTC\n",
    "        )\n",
    "    elif decision == 'sell':\n",
    "        order = MarketOrderRequest(\n",
    "            symbol=symbol,\n",
    "            qty=1,\n",
    "            side=OrderSide.SELL,\n",
    "            time_in_force=TimeInForce.GTC\n",
    "        )\n",
    "    \n",
    "    trading_client.submit_order(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of stock symbols to evaluate\n",
    "stocks = ['AAPL', 'MSFT', 'GOOGL']\n",
    "\n",
    "def get_stock_fundamentals(stock_symbol):\n",
    "    \"\"\"Fetches basic fundamental data for a given stock symbol using Finnhub API.\"\"\"\n",
    "    try:\n",
    "        # Get basic financials\n",
    "        financials = finnhub_client.company_basic_financials(stock_symbol, 'all')\n",
    "\n",
    "        # Extract relevant data\n",
    "        metric = financials['metric']\n",
    "        fundamentals = {\n",
    "            'symbol': stock_symbol,\n",
    "            'peRatioTTM': metric.get('peNormalizedAnnual', 'N/A'),\n",
    "            'pbRatio': metric.get('pbAnnual', 'N/A'),\n",
    "            'dividendYieldTTM': metric.get('currentDividendYieldTTM', 'N/A'),\n",
    "            'epsTTM': metric.get('epsTTM', 'N/A'),\n",
    "            'marketCapitalization': metric.get('marketCapitalization', 'N/A'),\n",
    "            '52WeekHigh': metric.get('52WeekHigh', 'N/A'),\n",
    "            '52WeekLow': metric.get('52WeekLow', 'N/A'),\n",
    "        }\n",
    "        return fundamentals\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {stock_symbol}: {e}\")\n",
    "        return None\n",
    "\n",
    "def evaluate_stocks(stock_list):\n",
    "    \"\"\"Evaluates a list of stocks and prints their fundamental data.\"\"\"\n",
    "    results = []\n",
    "    for stock in stock_list:\n",
    "        fundamentals = get_stock_fundamentals(stock)\n",
    "        if fundamentals:\n",
    "            results.append(fundamentals)\n",
    "    \n",
    "    return results\n",
    "\n",
    "import finnhub\n",
    "import os\n",
    "\n",
    "# List of stock symbols to evaluate\n",
    "stocks = ['AAPL', 'MSFT', 'GOOGL']\n",
    "\n",
    "def get_stock_fundamentals(stock_symbol):\n",
    "    \"\"\"Fetches basic fundamental data for a given stock symbol using Finnhub API.\"\"\"\n",
    "    try:\n",
    "        # Get basic financials\n",
    "        financials = finnhub_client.company_basic_financials(stock_symbol, 'all')\n",
    "\n",
    "        # Get current price\n",
    "        quote = finnhub_client.quote(stock_symbol)\n",
    "        current_price = quote['c']\n",
    "\n",
    "        # Extract relevant data\n",
    "        metric = financials['metric']\n",
    "        fundamentals = {\n",
    "            'symbol': stock_symbol,\n",
    "            'current_price': current_price,\n",
    "            '10DayAverageTradingVolume': metric.get('10DayAverageTradingVolume', 'N/A'),\n",
    "            '13WeekPriceReturnDaily': metric.get('13WeekPriceReturnDaily', 'N/A'),\n",
    "            '26WeekPriceReturnDaily': metric.get('26WeekPriceReturnDaily', 'N/A'),\n",
    "            '52WeekHigh': metric.get('52WeekHigh', 'N/A'),\n",
    "            '52WeekLow': metric.get('52WeekLow', 'N/A'),\n",
    "            '52WeekPriceReturnDaily': metric.get('52WeekPriceReturnDaily', 'N/A'),\n",
    "            '5DayPriceReturnDaily': metric.get('5DayPriceReturnDaily', 'N/A'),\n",
    "            'peRatioTTM': metric.get('peNormalizedAnnual', 'N/A'),\n",
    "            'pbRatio': metric.get('pbAnnual', 'N/A'),\n",
    "            'dividendYieldTTM': metric.get('currentDividendYieldTTM', 'N/A'),\n",
    "            'epsTTM': metric.get('epsTTM', 'N/A'),\n",
    "            'marketCapitalization': metric.get('marketCapitalization', 'N/A'),\n",
    "            'currentRatioAnnual': metric.get('currentRatioAnnual', 'N/A'),\n",
    "            'quickRatioAnnual': metric.get('quickRatioAnnual', 'N/A'),\n",
    "            'debt/equityAnnual': metric.get('totalDebt/totalEquityAnnual', 'N/A'),\n",
    "            'grossMarginAnnual': metric.get('grossMarginAnnual', 'N/A'),\n",
    "            'netProfitMarginAnnual': metric.get('netProfitMarginAnnual', 'N/A'),\n",
    "            'operatingMarginAnnual': metric.get('operatingMarginAnnual', 'N/A'),\n",
    "            'revenueGrowth3Y': metric.get('revenueGrowth3Y', 'N/A'),\n",
    "            'revenueGrowth5Y': metric.get('revenueGrowth5Y', 'N/A'),\n",
    "            'revenueGrowthQuarterlyYoy': metric.get('revenueGrowthQuarterlyYoy', 'N/A'),\n",
    "            'epsGrowth3Y': metric.get('epsGrowth3Y', 'N/A'),\n",
    "            'epsGrowth5Y': metric.get('epsGrowth5Y', 'N/A'),\n",
    "            'bookValuePerShareAnnual': metric.get('bookValuePerShareAnnual', 'N/A'),\n",
    "            'cashFlowPerShareTTM': metric.get('cashFlowPerShareTTM', 'N/A'),\n",
    "            'enterpriseValue': metric.get('enterpriseValue', 'N/A'),\n",
    "        }\n",
    "        return fundamentals\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {stock_symbol}: {e}\")\n",
    "        return None\n",
    "\n",
    "def evaluate_stocks(stock_list):\n",
    "    \"\"\"Evaluates a list of stocks and prints their fundamental data.\"\"\"\n",
    "    results = []\n",
    "    for stock in stock_list:\n",
    "        fundamentals = get_stock_fundamentals(stock)\n",
    "        if fundamentals:\n",
    "            results.append(fundamentals)\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    stock_fundamentals = evaluate_stocks(stocks)\n",
    "    for stock in stock_fundamentals:\n",
    "        print(stock)\n",
    "\n",
    "print(pd.DataFrame(stock_fundamentals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(finnhub_client.company_basic_financials('MSFT', 'All')).T.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpaca.trading.client import TradingClient\n",
    "from alpaca.trading.requests import GetAssetsRequest\n",
    "\n",
    "trading_client = TradingClient(ALPACA_API_KEY, ALPACA_SECRET_KEY, paper=False)\n",
    "\n",
    "# Get our account information.\n",
    "account = trading_client.get_account()\n",
    "\n",
    "# Check if our account is restricted from trading.\n",
    "if account.trading_blocked:\n",
    "    print('Account is currently restricted from trading.')\n",
    "\n",
    "# Check how much money we can use to open new positions.\n",
    "print('${} is available as buying power.'.format(account.buying_power))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_client.get_all_positions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"MSFT\"  # replace with your symbol\n",
    "url = f\"https://data.alpaca.markets/v2/stocks/{symbol}/quotes/latest\"\n",
    "\n",
    "headers = {\n",
    "    'accept': 'application/json',\n",
    "    'APCA-API-KEY-ID': ALPACA_API_KEY,\n",
    "    'APCA-API-SECRET-KEY': ALPACA_SECRET_KEY\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "data = response.json()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://data.alpaca.markets/v2/positions\"\n",
    "headers = {\n",
    "    'accept': 'application/json',\n",
    "    'APCA-API-KEY-ID': ALPACA_API_KEY,\n",
    "    'APCA-API-SECRET-KEY': ALPACA_SECRET_KEY\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "data = response.json()\n",
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
